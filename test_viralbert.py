# test_viralbert.py - –¢–µ—Å—Ç—ã –¥–ª—è ViralBERT v2

import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModel
from pathlib import Path
import time

# ========== –ê–†–•–ò–¢–ï–ö–¢–£–†–ê –ú–û–î–ï–õ–ò ==========
class MultiTaskClassifier(nn.Module):
    def __init__(self, model_path, num_emotions=28, hidden_size=768):
        super().__init__()
        self.bert = AutoModel.from_pretrained(model_path)
        
        self.popularity_head = nn.Sequential(
            nn.Linear(hidden_size, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 1)
        )
        
        self.emotion_head = nn.Sequential(
            nn.Linear(hidden_size, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, num_emotions)
        )
    
    def forward(self, input_ids, attention_mask, task='both'):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        cls_embedding = outputs.last_hidden_state[:, 0, :]
        
        pop_out = None
        emo_out = None
        
        if task in ['popularity', 'both']:
            pop_out = self.popularity_head(cls_embedding)
        if task in ['emotion', 'both']:
            emo_out = self.emotion_head(cls_embedding)
        
        return pop_out, emo_out

# ========== –≠–ú–û–¶–ò–ò ==========
EMOTION_NAMES = [
    'admiration', 'amusement', 'anger', 'annoyance', 'approval',
    'caring', 'confusion', 'curiosity', 'desire', 'disappointment',
    'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear',
    'gratitude', 'grief', 'joy', 'love', 'nervousness',
    'optimism', 'pride', 'realization', 'relief', 'remorse',
    'sadness', 'surprise', 'neutral'
]

EMOTION_WEIGHTS = {
    'amusement': 0.15, 'excitement': 0.12, 'joy': 0.10,
    'surprise': 0.08, 'admiration': 0.07, 'love': 0.06,
    'anger': 0.05, 'fear': 0.04, 'disgust': 0.03,
    'sadness': -0.02, 'neutral': -0.05
}

# ========== –ó–ê–ì–†–£–ó–ö–ê –ú–û–î–ï–õ–ò ==========
print("üì• –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å...")

# –í–ê–ñ–ù–û: –£–∫–∞–∂–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—É—Ç–∏ (–∏–∑ —Ç–≤–æ–µ–≥–æ ShortsBot –ø—Ä–æ–µ–∫—Ç–∞)
MODEL_PATH = r"C:\Users\konst\OneDrive\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\ShortsBot-main\ShortsBot-main\models\rubert-base"
CLASSIFIER_PATH = r"C:\Users\konst\OneDrive\–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª\ShortsBot-main\ShortsBot-main\models\multitask_best.pth"

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
if not Path(MODEL_PATH).exists():
    raise FileNotFoundError(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞ –ø–∞–ø–∫–∞ –º–æ–¥–µ–ª–∏: {MODEL_PATH}")
if not Path(CLASSIFIER_PATH).exists():
    raise FileNotFoundError(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª –≤–µ—Å–æ–≤: {CLASSIFIER_PATH}")

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ)
import warnings
warnings.filterwarnings('ignore', message='.*incorrect regex pattern.*')
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
model = MultiTaskClassifier(MODEL_PATH, num_emotions=28, hidden_size=768)

checkpoint = torch.load(CLASSIFIER_PATH, map_location='cpu', weights_only=False)
if 'model_state_dict' in checkpoint:
    model.load_state_dict(checkpoint['model_state_dict'])
else:
    model.load_state_dict(checkpoint)

model.eval()
print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!\n")

# ========== –§–£–ù–ö–¶–ò–Ø –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø ==========
def predict(text: str, show_details=False):
    """–ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –≤–∏—Ä—É—Å–Ω–æ—Å—Ç—å –∏ —ç–º–æ—Ü–∏–∏ –¥–ª—è —Ç–µ–∫—Å—Ç–∞"""
    encoding = tokenizer(
        text,
        max_length=128,
        padding='max_length',
        truncation=True,
        return_tensors='pt'
    )
    
    with torch.no_grad():
        pop_logits, emo_logits = model(encoding['input_ids'], encoding['attention_mask'], task='both')
        
        # –í–∏—Ä—É—Å–Ω–æ—Å—Ç—å
        base_viral = torch.sigmoid(pop_logits).item()
        
        # –≠–º–æ—Ü–∏–∏
        emo_probs = torch.sigmoid(emo_logits).squeeze(0).numpy()
    
    # –¢–æ–ø —ç–º–æ—Ü–∏–∏
    top_emotions = []
    emotion_boost = 0.0
    
    for i, (name, score) in enumerate(zip(EMOTION_NAMES, emo_probs)):
        if score >= 0.3:
            top_emotions.append((name, float(score)))
            emotion_boost += EMOTION_WEIGHTS.get(name, 0) * score
    
    top_emotions = sorted(top_emotions, key=lambda x: x[1], reverse=True)
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–∫–æ—Ä
    final_score = base_viral * 0.8 + emotion_boost * 0.2
    final_score = max(0.0, min(1.0, final_score))
    
    # –í—ã–≤–æ–¥
    if show_details:
        print(f"üìä –ë–∞–∑–æ–≤–∞—è –≤–∏—Ä—É—Å–Ω–æ—Å—Ç—å: {base_viral:.2%}")
        print(f"üé≠ –≠–º–æ—Ü–∏–∏ (—Ç–æ–ø-3):")
        for emo, score in top_emotions[:3]:
            print(f"   ‚Ä¢ {emo}: {score:.2%}")
        print(f"‚ö° Emotion boost: {emotion_boost:+.3f}")
        print(f"üéØ –ò—Ç–æ–≥–æ–≤–∞—è –≤–∏—Ä—É—Å–Ω–æ—Å—Ç—å: {final_score:.2%}\n")
    
    return {
        'viral_score': final_score,
        'base_viral': base_viral,
        'emotions': top_emotions,
        'emotion_boost': emotion_boost
    }

# ========== –¢–ï–°–¢–û–í–´–ï –ü–†–ò–ú–ï–†–´ ==========
print("=" * 60)
print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ò")
print("=" * 60)

test_cases = [
    # –í—ã—Å–æ–∫–∞—è –≤–∏—Ä—É—Å–Ω–æ—Å—Ç—å
    {
        "text": "–≠–¢–û –ù–ï–í–ï–†–û–Ø–¢–ù–û! –Ø –ø—Ä–æ—Å—Ç–æ –≤ —à–æ–∫–µ –æ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤! üò±",
        "expected": "high",
        "description": "–≠–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å –∫–∞–ø—Å–æ–º"
    },
    {
        "text": "–ö–∞–∫ —è –∑–∞—Ä–∞–±–æ—Ç–∞–ª –º–∏–ª–ª–∏–æ–Ω –∑–∞ –º–µ—Å—è—Ü: –°–ï–ö–†–ï–¢–ù–´–ô –º–µ—Ç–æ–¥",
        "expected": "high",
        "description": "–ö–ª–∏–∫–±–µ–π—Ç –ø—Ä–æ –¥–µ–Ω—å–≥–∏"
    },
    {
        "text": "–í—Ä–∞—á–∏ –≤ –®–û–ö–ï! –≠—Ç–æ—Ç –ø—Ä–æ–¥—É–∫—Ç —Ç–≤–æ—Ä–∏—Ç —á—É–¥–µ—Å–∞",
        "expected": "high",
        "description": "–°–µ–Ω—Å–∞—Ü–∏–æ–Ω–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫"
    },
    
    # –°—Ä–µ–¥–Ω—è—è –≤–∏—Ä—É—Å–Ω–æ—Å—Ç—å
    {
        "text": "–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Ñ–∞–∫—Ç –æ –∫–æ—Å–º–æ—Å–µ, –∫–æ—Ç–æ—Ä—ã–π –≤—ã –Ω–µ –∑–Ω–∞–ª–∏",
        "expected": "medium",
        "description": "–ü–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç"
    },
    {
        "text": "5 –ª–∞–π—Ñ—Ö–∞–∫–æ–≤ –¥–ª—è –ø–æ–≤—ã—à–µ–Ω–∏—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏",
        "expected": "medium",
        "description": "–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã"
    },
    
    # –ù–∏–∑–∫–∞—è –≤–∏—Ä—É—Å–Ω–æ—Å—Ç—å
    {
        "text": "–°–µ–≥–æ–¥–Ω—è —è —Ö–æ–¥–∏–ª –≤ –º–∞–≥–∞–∑–∏–Ω –∏ –∫—É–ø–∏–ª –º–æ–ª–æ–∫–æ",
        "expected": "low",
        "description": "–û–±—ã—á–Ω–∞—è –±—ã—Ç–æ–≤–∞—è —Ñ—Ä–∞–∑–∞"
    },
    {
        "text": "–û—Ç—á—ë—Ç –æ —Ä–∞–±–æ—Ç–µ –∑–∞ –≤—Ç–æ—Ä–æ–π –∫–≤–∞—Ä—Ç–∞–ª 2024 –≥–æ–¥–∞",
        "expected": "low",
        "description": "–§–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç"
    },
    {
        "text": "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–≥–æ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è",
        "expected": "low",
        "description": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"
    },
]

# ========== –ó–ê–ü–£–°–ö –¢–ï–°–¢–û–í ==========
results = {"high": 0, "medium": 0, "low": 0}
correct = 0

for i, test in enumerate(test_cases, 1):
    print(f"\n[–¢–ï–°–¢ {i}] {test['description']}")
    print(f"üìù –¢–µ–∫—Å—Ç: \"{test['text']}\"")
    print(f"üéØ –û–∂–∏–¥–∞–µ–º: {test['expected'].upper()}")
    print("-" * 60)
    
    result = predict(test['text'], show_details=True)
    
    # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –ø–æ—Ä–æ–≥–∞–º
    score = result['viral_score']
    if score >= 0.7:
        predicted = "high"
    elif score >= 0.4:
        predicted = "medium"
    else:
        predicted = "low"
    
    results[predicted] += 1
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏
    if predicted == test['expected']:
        print("‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û")
        correct += 1
    else:
        print(f"‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û (–ø–æ–ª—É—á–∏–ª–∏: {predicted.upper()})")

# ========== –ò–¢–û–ì–ò ==========
print("\n" + "=" * 60)
print("üìä –ò–¢–û–ì–ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
print("=" * 60)
print(f"‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤: {correct}/{len(test_cases)} ({correct/len(test_cases)*100:.1f}%)")
print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π:")
print(f"  ‚Ä¢ HIGH:   {results['high']}")
print(f"  ‚Ä¢ MEDIUM: {results['medium']}")
print(f"  ‚Ä¢ LOW:    {results['low']}")

# ========== –ö–ê–°–¢–û–ú–ù–´–ï –¢–ï–ö–°–¢–´ ==========
print("\n" + "=" * 60)
print("üé® –¢–ï–°–¢ –ù–ê –°–í–û–ò–• –¢–ï–ö–°–¢–ê–•")
print("=" * 60)
print("–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (–∏–ª–∏ 'exit' –¥–ª—è –≤—ã—Ö–æ–¥–∞):\n")

while True:
    try:
        user_text = input("üìù –í–∞—à —Ç–µ–∫—Å—Ç: ").strip()
        if user_text.lower() == 'exit':
            break
        if not user_text:
            continue
        
        print()
        start_time = time.time()
        result = predict(user_text, show_details=True)
        elapsed = time.time() - start_time
        
        print(f"‚è±Ô∏è  –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {elapsed:.3f}—Å\n")
        
    except KeyboardInterrupt:
        break

print("\nüëã –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
