from transformers import AutoTokenizer, AutoModel
import torch

print("üì• –°–∫–∞—á–∏–≤–∞—é rubert-base-cased...")

model_name = "ai-forever/ruBert-base"  # –∏–ª–∏ "cointegrated/rubert-base-cased"

try:
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    base_model = AutoModel.from_pretrained(model_name)
    
    print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–∞—á–∞–Ω–∞!")
    print(f"üìä –†–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {base_model.config.hidden_size}")
    print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: ~180M")
    
    save_dir = "./models/rubert-base"
    tokenizer.save_pretrained(save_dir)
    base_model.save_pretrained(save_dir)
    
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {save_dir}")
    
    # –¢–µ—Å—Ç
    test_text = "–≠—Ç–æ –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è!"
    inputs = tokenizer(test_text, return_tensors='pt', padding=True, truncation=True)
    with torch.no_grad():
        outputs = base_model(**inputs)
        embeddings = outputs.last_hidden_state[:, 0, :]
    
    print(f"‚úÖ –í–µ–∫—Ç–æ—Ä —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏: {embeddings.shape[1]}")
    
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
