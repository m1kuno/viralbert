from transformers import AutoTokenizer, AutoModel
import torch

print("üì• –°–∫–∞—á–∏–≤–∞—é rubert-base —Å safetensors...")

model_name = "ai-forever/ruBert-base"

try:
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    base_model = AutoModel.from_pretrained(
        model_name,
        use_safetensors=True  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
    )
    
    print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–∞—á–∞–Ω–∞!")
    print(f"üìä Hidden size: {base_model.config.hidden_size}")
    
    save_dir = "./models/rubert-base"
    tokenizer.save_pretrained(save_dir)
    base_model.save_pretrained(save_dir, safe_serialization=True)
    
    print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {save_dir}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞
    test = "–≠—Ç–æ —Ç–µ—Å—Ç"
    inputs = tokenizer(test, return_tensors='pt')
    with torch.no_grad():
        outputs = base_model(**inputs)
        emb = outputs.last_hidden_state[:, 0, :]
    
    print(f"‚úÖ –í–µ–∫—Ç–æ—Ä: {emb.shape[1]} dims")
    
except Exception as e:
    print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
